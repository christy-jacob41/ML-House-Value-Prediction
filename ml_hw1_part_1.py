# -*- coding: utf-8 -*-
"""ML HW1 Part 1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1AvwrKm2rliJ6lOPXoSLEnHtvNGmJPN4G
"""

# importing pandas, matplotlib, and seaborn
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np

# importing real estate evaluation dataset
file = 'https://archive.ics.uci.edu/ml/machine-learning-databases/00477/Real%20estate%20valuation%20data%20set.xlsx'
df = pd.read_excel(file)

print(df)

# dropping row if there are missing values or NA
df = df.dropna(axis=0)
print(df)

# dropping duplicates and updating the dataframe
df.drop_duplicates(keep='first', inplace=True)
print(df)

# no categorical variables to worry about

# the "No" column is unnecessary so I will drop it
df = df.drop(columns=['No'])
print(df)

# creating a correlation matrix
correlation_matrix = df.corr().round(2)

# showing heat map of correlation matrix
sns.heatmap(data=correlation_matrix, annot=True)

# normalizing data as part of preprocessing
from sklearn.preprocessing import StandardScaler

X = df[['X1 transaction date', 'X2 house age', 'X3 distance to the nearest MRT station', 'X4 number of convenience stores', 'X5 latitude', 'X6 longitude']]
Y = df['Y house price of unit area']

# transforming data to make it become standardized(normalized) using StandardScaler
s = StandardScaler()
X = pd.DataFrame(s.fit(X).fit_transform(X), columns=['X1 transaction date', 'X2 house age', 'X3 distance to the nearest MRT station', 'X4 number of convenience stores', 'X5 latitude', 'X6 longitude'])
X['Y house price of unit area'] = list(Y)
print(X)

# using train_test_split to split dataframe into trainig and testing dataset
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error
from sklearn.metrics import r2_score

# using an 80% training and 20% testing split
X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2, random_state=5)
print(X_train.shape)
print(X_test.shape)
print(Y_train.shape)
print(Y_test.shape)

# function to perform gradient descent
def gradient_descent(X, Y, learning_rate=0.1, n_iter=1000, batch_size=40):
    
    weights = np.random.randn(1,6)  # Randomly initializing weights
    intercept = np.random.randn(1,1)   # Random intercept value
    
    current_iter=1
    
    # loop for number of iterations
    while current_iter <= n_iter:
        
        # getting sample
        temp = X.sample(batch_size)

        # separating X and Y
        X_temp = temp.iloc[:,0:6].values
        Y_temp = temp.iloc[:,-1].values
        
        Lw = weights
        Li = intercept
        
        mse = 0
        Y_pred = []
        sq_loss = []
        
        for i in range(batch_size):
              
            # calculate gradients 
            Lw = (-2/batch_size * X_temp[i]) * (Y_temp[i] - np.dot(X_temp[i],weights.T) - intercept)
            Li = (-2/batch_size) * (Y_temp[i] - np.dot(X_temp[i],weights.T) - intercept)
            
            # changing weights
            weights = weights - learning_rate * Lw
            intercept = intercept - learning_rate * Li
            
            # calculating predicted Y values
            Y_predicted = np.dot(X_temp[i],weights.T)
            Y_pred.append(Y_predicted)
        
        # getting mse
        mse = mean_squared_error(Y_pred, Y_temp)
            
        # performing next iteration and updating learning rate    
        current_iter+=1
        learning_rate = learning_rate/1.01
        
    return weights,intercept

# function to predict on test data
def predict_test(x,weights,intercept):
    Y_pred=[]
    for i in range(len(x)):
        temp_ = x
        X_test = temp_.iloc[:,0:6].values
        Y = np.asscalar(np.dot(weights,X_test[i])+intercept)
        Y_pred.append(Y)
    return np.array(Y_pred)
weights,intercept = gradient_descent(X_train,Y_train)
Y_pred_grad_desc = predict_test(X_test,weights,intercept)
print(weights)
print(intercept)

plt.figure(figsize=(25,6))
plt.plot(Y_test, label='Actual')
plt.plot(Y_pred_grad_desc, label='Predicted')
plt.legend(prop={'size': 10})
plt.show()
print('Root Mean Squared Error :',np.sqrt(mean_squared_error(Y_test, Y_pred_grad_desc)))
print('R2 score :', r2_score(Y_test, Y_pred_grad_desc))

weights,intercept = gradient_descent(X_train,Y_train, learning_rate=0.01)
Y_pred_grad_desc = predict_test(X_test,weights,intercept)
plt.plot(Y_test, label='Actual')
plt.plot(Y_pred_grad_desc, label='Predicted')
plt.legend(prop={'size': 10})
print(weights)
print(intercept)
print('Root Mean Squared Error :', np.sqrt(mean_squared_error(Y_test, Y_pred_grad_desc)))
print('R2 score :', r2_score(Y_test, Y_pred_grad_desc))

weights,intercept = gradient_descent(X_train,Y_train, learning_rate=0.001)
Y_pred_grad_desc = predict_test(X_test,weights,intercept)
plt.plot(Y_test, label='Actual')
plt.plot(Y_pred_grad_desc, label='Predicted')
plt.legend(prop={'size': 10})
print(weights)
print(intercept)
print('Root Mean Squared Error :', np.sqrt(mean_squared_error(Y_test, Y_pred_grad_desc)))
print('R2 score :', r2_score(Y_test, Y_pred_grad_desc))

weights,intercept = gradient_descent(X_train,Y_train, learning_rate=0.4)
Y_pred_grad_desc = predict_test(X_test,weights,intercept)
plt.plot(Y_test, label='Actual')
plt.plot(Y_pred_grad_desc, label='Predicted')
plt.legend(prop={'size': 10})
print(weights)
print(intercept)
print('Root Mean Squared Error :', np.sqrt(mean_squared_error(Y_test, Y_pred_grad_desc)))
print('R2 score :', r2_score(Y_test, Y_pred_grad_desc))

weights,intercept = gradient_descent(X_train,Y_train, learning_rate=0.4, n_iter=2000)
Y_pred_grad_desc = predict_test(X_test,weights,intercept)
plt.plot(Y_test, label='Actual')
plt.plot(Y_pred_grad_desc, label='Predicted')
plt.legend(prop={'size': 10})
print(weights)
print(intercept)
print('Root Mean Squared Error :', np.sqrt(mean_squared_error(Y_test, Y_pred_grad_desc)))
print('R2 score :', r2_score(Y_test, Y_pred_grad_desc))

weights,intercept = gradient_descent(X_train,Y_train, learning_rate=0.4, n_iter=200)
Y_pred_grad_desc = predict_test(X_test,weights,intercept)
plt.plot(Y_test, label='Actual')
plt.plot(Y_pred_grad_desc, label='Predicted')
plt.legend(prop={'size': 10})
print(weights)
print(intercept)
print('Root Mean Squared Error :', np.sqrt(mean_squared_error(Y_test, Y_pred_grad_desc)))
print('R2 score :', r2_score(Y_test, Y_pred_grad_desc))

weights,intercept = gradient_descent(X_train,Y_train, learning_rate=0.4, n_iter=5000)
Y_pred_grad_desc = predict_test(X_test,weights,intercept)
plt.plot(Y_test, label='Actual')
plt.plot(Y_pred_grad_desc, label='Predicted')
plt.legend(prop={'size': 10})
print(weights)
print(intercept)
print('Root Mean Squared Error :', np.sqrt(mean_squared_error(Y_test, Y_pred_grad_desc)))
print('R2 score :', r2_score(Y_test, Y_pred_grad_desc))

weights,intercept = gradient_descent(X_train,Y_train, learning_rate=0.4, n_iter=50000)
Y_pred_grad_desc = predict_test(X_test,weights,intercept)
plt.plot(Y_test, label='Actual')
plt.plot(Y_pred_grad_desc, label='Predicted')
plt.legend(prop={'size': 10})
print(weights)
print(intercept)
print('Root Mean Squared Error :', np.sqrt(mean_squared_error(Y_test, Y_pred_grad_desc)))
print('R2 score :', r2_score(Y_test, Y_pred_grad_desc))

# function to perform gradient descent
def gradient_descent(X, Y, learning_rate=0.1, n_iter=1000, batch_size=40):
    
    weights = np.random.randn(1,5)  # Randomly initializing weights
    intercept = np.random.randn(1,1)   # Random intercept value
    
    current_iter=1
    
    # loop for number of iterations
    while current_iter <= n_iter:
        
        # getting sample
        temp = X.sample(batch_size)

        # separating X and Y
        X_temp = temp.iloc[:,0:5].values
        Y_temp = temp.iloc[:,-1].values
        
        Lw = weights
        Li = intercept
        
        mse = 0
        Y_pred = []
        sq_loss = []
        
        for i in range(batch_size):
              
            # calculate gradients 
            Lw = (-2/batch_size * X_temp[i]) * (Y_temp[i] - np.dot(X_temp[i],weights.T) - intercept)
            Li = (-2/batch_size) * (Y_temp[i] - np.dot(X_temp[i],weights.T) - intercept)
            
            # changing weights
            weights = weights - learning_rate * Lw
            intercept = intercept - learning_rate * Li
            
            # calculating predicted Y values
            Y_predicted = np.dot(X_temp[i],weights.T)
            Y_pred.append(Y_predicted)
        
        # getting mse
        mse = mean_squared_error(Y_pred, Y_temp)
            
        # performing next iteration and updating learning rate    
        current_iter+=1
        learning_rate = learning_rate/1.01
        
    return weights,intercept

# function to predict on test data
def predict_test(x,weights,intercept):
    Y_pred=[]
    for i in range(len(x)):
        temp_ = x
        X_test = temp_.iloc[:,0:5].values
        Y = np.asscalar(np.dot(weights,X_test[i])+intercept)
        Y_pred.append(Y)
    return np.array(Y_pred)

X_train.drop(labels='X1 transaction date', axis=1)
X_test.drop(labels='X1 transaction date', axis=1)
weights,intercept = gradient_descent(X_train,Y_train, n_iter=5000)
Y_pred_grad_desc = predict_test(X_test,weights,intercept)
print(weights)
print(intercept)
print('Root Mean Squared Error :', np.sqrt(mean_squared_error(Y_test, Y_pred_grad_desc)))
print('R2 score :', r2_score(Y_test, Y_pred_grad_desc))
plt.plot(Y_test, label='Actual')
plt.plot(Y_pred_grad_desc, label='Predicted')
plt.legend(prop={'size': 10})

weights,intercept = gradient_descent(X_train,Y_train, learning_rate=0.4, n_iter=5000)
Y_pred_grad_desc = predict_test(X_test,weights,intercept)
plt.plot(Y_test, label='Actual')
plt.plot(Y_pred_grad_desc, label='Predicted')
plt.legend(prop={'size': 10})
print(weights)
print(intercept)
print('Root Mean Squared Error :', np.sqrt(mean_squared_error(Y_test, Y_pred_grad_desc)))
print('R2 score :', r2_score(Y_test, Y_pred_grad_desc))

sns.set(rc={'figure.figsize':(11.7,8.27)})
sns.distplot(df['X2 house age'], bins=50)
plt.show()

sns.distplot(df['Y house price of unit area'], bins=50)

sns.distplot(df['X1 transaction date'], bins=50)

sns.distplot(df['X3 distance to the nearest MRT station'], bins=50)

sns.distplot(df['X4 number of convenience stores'], bins=50)